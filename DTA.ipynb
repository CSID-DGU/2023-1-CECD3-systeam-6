{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMU5Hpcq+dhdX9gOfJIel2J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19274,"status":"ok","timestamp":1700137990715,"user":{"displayName":"ᄒᄋ","userId":"02524461225617544295"},"user_tz":-540},"id":"jEd_qSSe5xzW","outputId":"d050011e-8f27-4e27-ea57-4a6210da13c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":154499,"status":"ok","timestamp":1700138145195,"user":{"displayName":"ᄒᄋ","userId":"02524461225617544295"},"user_tz":-540},"id":"FTXmImpOG309","outputId":"d1ba33de-75b3-4a1a-a5a8-358e5210f682"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n","Collecting torch==1.11.0+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp310-cp310-linux_x86_64.whl (1637.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 GB\u001b[0m \u001b[31m898.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.12.0+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.12.0%2Bcu113-cp310-cp310-linux_x86_64.whl (22.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio==0.11.0+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.11.0%2Bcu113-cp310-cp310-linux_x86_64.whl (2.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0+cu113) (4.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113) (9.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (2023.7.22)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.0+cu118\n","    Uninstalling torch-2.1.0+cu118:\n","      Successfully uninstalled torch-2.1.0+cu118\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.16.0+cu118\n","    Uninstalling torchvision-0.16.0+cu118:\n","      Successfully uninstalled torchvision-0.16.0+cu118\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.1.0+cu118\n","    Uninstalling torchaudio-2.1.0+cu118:\n","      Successfully uninstalled torchaudio-2.1.0+cu118\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.11.0+cu113 which is incompatible.\n","torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.11.0+cu113 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.11.0+cu113 torchaudio-0.11.0+cu113 torchvision-0.12.0+cu113\n"]}],"source":["!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1407,"status":"ok","timestamp":1700138146539,"user":{"displayName":"ᄒᄋ","userId":"02524461225617544295"},"user_tz":-540},"id":"4ycsaEU7y_GP","outputId":"06a0e313-10c0-48c9-e221-36b6b2717801"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.11.0 cu113\n"]}],"source":["import torch\n","\n","def format_pytorch_version(version):\n","  return version.split('+')[0]\n","\n","TORCH_version = torch.__version__\n","\n","TORCH = format_pytorch_version(TORCH_version)\n","\n","def format_cuda_version(version):\n","  return 'cu' + version.replace('.', '')\n","\n","CUDA_version = torch.version.cuda\n","\n","CUDA = format_cuda_version(CUDA_version)\n","print(TORCH, CUDA)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25386,"status":"ok","timestamp":1700138171757,"user":{"displayName":"ᄒᄋ","userId":"02524461225617544295"},"user_tz":-540},"id":"hh7Fo36wx-0v","outputId":"abe60a84-a682-4dbc-c02c-53dad55308f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://data.pyg.org/whl/torch-1.11.0+cu113.html\n","Collecting torch-geometric==2.1.0\n","  Downloading torch_geometric-2.1.0.tar.gz (467 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.5/467.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting torch-sparse==0.6.15\n","  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_sparse-0.6.15-cp310-cp310-linux_x86_64.whl (3.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-scatter==2.0.9\n","  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_scatter-2.0.9-cp310-cp310-linux_x86_64.whl (7.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-cluster==1.6.0\n","  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_cluster-1.6.0-cp310-cp310-linux_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-spline-conv==1.2.1\n","  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_spline_conv-1.2.1-cp310-cp310-linux_x86_64.whl (750 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.3/750.3 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.1.0) (4.66.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.1.0) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.1.0) (1.11.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.1.0) (3.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.1.0) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.1.0) (3.1.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.1.0) (1.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.1.0) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.1.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.1.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.1.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.1.0) (2023.7.22)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.1.0) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.1.0) (3.2.0)\n","\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'torch-geometric' candidate (version 2.1.0 at https://files.pythonhosted.org/packages/01/82/69a09acb03e26202b7a0a2f65359e35e2d359a143f0dc4391504e0c0260c/torch_geometric-2.1.0.tar.gz (from https://pypi.org/simple/torch-geometric/) (requires-python:>=3.7))\n","Reason for being yanked: Missing ninja templates\u001b[0m\u001b[33m\n","\u001b[0mBuilding wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-2.1.0-py3-none-any.whl size=687148 sha256=7381eaded828ab145b53662f393d6eb9faed319da7a2d85567bdc8d11c23e219\n","  Stored in directory: /root/.cache/pip/wheels/cb/3f/b9/f853f84dfc8f4ac802260c77f25f657c2c86010c66fc535f5d\n","Successfully built torch-geometric\n","Installing collected packages: torch-spline-conv, torch-scatter, torch-cluster, torch-sparse, torch-geometric\n","Successfully installed torch-cluster-1.6.0 torch-geometric-2.1.0 torch-scatter-2.0.9 torch-sparse-0.6.15 torch-spline-conv-1.2.1\n"]}],"source":["!pip install torch-geometric==2.1.0\\\n","  torch-sparse==0.6.15 \\\n","  torch-scatter==2.0.9 \\\n","  torch-cluster==1.6.0 \\\n","  torch-spline-conv==1.2.1 \\\n","  -f https://data.pyg.org/whl/torch-1.11.0+cu113.html"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37865,"status":"ok","timestamp":1700138209519,"user":{"displayName":"ᄒᄋ","userId":"02524461225617544295"},"user_tz":-540},"id":"kpQJ9hr0o3Xo","outputId":"f7c6b2ce-a1c8-4650-b44b-72567c393bbd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.19.3-py3-none-any.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.19,>=0.14 (from transformers)\n","  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.19.3 safetensors-0.4.0 tokenizers-0.15.0 transformers-4.35.2\n"]}],"source":["pip install transformers"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18334,"status":"ok","timestamp":1700138227790,"user":{"displayName":"ᄒᄋ","userId":"02524461225617544295"},"user_tz":-540},"id":"vu9wswcEslWF","outputId":"5f6b8918-9cc2-4116-eaac-b8264917f7d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install rdkit-pypi -qqq"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"wZjHeRojff1O","executionInfo":{"status":"ok","timestamp":1700138233574,"user_tz":-540,"elapsed":5871,"user":{"displayName":"ᄒᄋ","userId":"02524461225617544295"}}},"outputs":[],"source":["import sys\n","#sys.path.append('/usr/local/lib/python3.7/site-packages/')\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import json,pickle\n","import networkx as nx\n","from math import sqrt\n","from random import shuffle\n","from collections import OrderedDict\n","from scipy import stats\n","from IPython.display import SVG\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import Sequential, Linear, ReLU\n","from rdkit import Chem\n","from rdkit.Chem.Draw import IPythonConsole\n","from rdkit.Chem import rdDepictor\n","from rdkit.Chem.Draw import rdMolDraw2D\n","from rdkit.Chem import MolFromSmiles\n","from torch_geometric import data as DATA\n","from torch_geometric.data import InMemoryDataset\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.nn import GCNConv, global_max_pool as gmp\n","from torch_geometric.nn import GCNConv, GATConv, GINConv, global_add_pool\n","from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"P788q6urNkCr","executionInfo":{"status":"ok","timestamp":1700138233575,"user_tz":-540,"elapsed":586,"user":{"displayName":"ᄒᄋ","userId":"02524461225617544295"}}},"outputs":[],"source":["def one_of_k_encoding(x, allowable_set):\n","    if x not in allowable_set:\n","        raise Exception(\"input {0} not in allowable set{1}:\".format(x, allowable_set))\n","    return list(map(lambda s: x == s, allowable_set))"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"iKEGy8oRNj5Z","executionInfo":{"status":"ok","timestamp":1700138233575,"user_tz":-540,"elapsed":582,"user":{"displayName":"ᄒᄋ","userId":"02524461225617544295"}}},"outputs":[],"source":["def one_of_k_encoding_unk(x, allowable_set):\n","    if x not in allowable_set:\n","        x = allowable_set[-1]\n","    return list(map(lambda s: x == s, allowable_set))"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"BorYGkFxNa0s","executionInfo":{"status":"ok","timestamp":1700138233576,"user_tz":-540,"elapsed":579,"user":{"displayName":"ᄒᄋ","userId":"02524461225617544295"}}},"outputs":[],"source":["def atom_features(atom):\n","    return np.array(one_of_k_encoding_unk(atom.GetSymbol(),['C', 'N', 'O', 'S', 'F', 'Si', 'P', 'Cl', 'Br', 'Mg', 'Na','Ca', 'Fe', 'As', 'Al', 'I', 'B', 'V', 'K', 'Tl', 'Yb','Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn', 'H','Li', 'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'In', 'Mn', 'Zr','Cr', 'Pt', 'Hg', 'Pb', 'Unknown']) +\n","                    one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4, 5, 6,7,8,9,10]) +\n","                    one_of_k_encoding_unk(atom.GetTotalNumHs(), [0, 1, 2, 3, 4, 5, 6,7,8,9,10]) +\n","                    one_of_k_encoding_unk(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5, 6,7,8,9,10]) +\n","                    [atom.GetIsAromatic()])"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"EnCT0OcyNrVc","executionInfo":{"status":"ok","timestamp":1700138233576,"user_tz":-540,"elapsed":578,"user":{"displayName":"ᄒᄋ","userId":"02524461225617544295"}}},"outputs":[],"source":["# SMILES 문자열로부터 분자 그래프 데이터 생성\n","def smiles_to_graph(smiles):\n","    mol = Chem.MolFromSmiles(smiles)\n","\n","    c_size = mol.GetNumAtoms() # 분자에 소속되어 있는 원자의 개수\n","\n","    features = []\n","\n","    # 원자 특성 정보 수집\n","    for atom in mol.GetAtoms():\n","        feature = atom_features(atom)\n","        features.append( feature / sum(feature) )\n","\n","    edges = []\n","    # 원자 연결 구조 정보를 통해 인접 정보 수집\n","    for bond in mol.GetBonds():\n","        edges.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()]) # 연결 구조 정보 : 시작 원자 index, 끝 원자 index\n","\n","    # 연결 구조 정보를 통한 방향 그래프 생성\n","    g = nx.Graph(edges).to_directed()\n","    edge_index = []\n","    for e1, e2 in g.edges:\n","        edge_index.append([e1, e2])\n","\n","    return c_size, features, edge_index"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"wSi7IMHSgPbd","executionInfo":{"status":"ok","timestamp":1700138945064,"user_tz":-540,"elapsed":574,"user":{"displayName":"ᄒᄋ","userId":"02524461225617544295"}}},"outputs":[],"source":["class TestbedDataset(InMemoryDataset):\n","    def __init__(self, root='/tmp', dataset='kiba',\n","                 xd=None, xt=None, y=None, transform=None,\n","                 pre_transform=None,smiles_graph=None):\n","\n","        super(TestbedDataset, self).__init__(root, transform, pre_transform)\n","\n","        self.dataset = dataset\n","\n","        if os.path.isfile(self.processed_paths[0]):\n","            print('Pre-processed data found: {}, loading ...'.format(self.processed_paths[0]))\n","            self.data, self.slices = torch.load(self.processed_paths[0])\n","        else:\n","            print('Pre-processed data {} not found, doing pre-processing...'.format(self.processed_paths[0]))\n","            self.process(xd, xt, y,smiles_graph)\n","            self.data, self.slices = torch.load(self.processed_paths[0])\n","\n","    @property\n","    def raw_file_names(self):\n","        pass\n","\n","    @property\n","    def processed_file_names(self):\n","        return [self.dataset + '.pt']\n","\n","    def download(self):\n","        pass\n","\n","    def _download(self):\n","        pass\n","\n","    def _process(self):\n","        if not os.path.exists(self.processed_dir):\n","            os.makedirs(self.processed_dir)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"sr7gWLQEpS7n","executionInfo":{"status":"ok","timestamp":1700138236020,"user_tz":-540,"elapsed":3016,"user":{"displayName":"ᄒᄋ","userId":"02524461225617544295"}}},"outputs":[],"source":["from transformers import BertModel, BertTokenizer\n","import re\n","\n","class GINConvNet(torch.nn.Module):\n","    def __init__(self, n_output=1, num_features_xd=78, num_features_xt=25,\n","                 n_filters=32, embed_dim=128, output_dim=128, dropout=0.2):\n","\n","        super(GINConvNet, self).__init__()\n","\n","        dim = 32\n","\n","        # 약물 분자 표현을 위한 GIN 층 구성\n","        self.dropout = nn.Dropout(dropout)\n","        self.relu = nn.ReLU()\n","        self.n_output = n_output\n","        nn1 = Sequential(Linear(num_features_xd, dim), ReLU(), Linear(dim, dim))\n","        self.conv1 = GINConv(nn1)\n","        self.bn1 = torch.nn.BatchNorm1d(dim)\n","\n","        nn2 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n","        self.conv2 = GINConv(nn2)\n","        self.bn2 = torch.nn.BatchNorm1d(dim)\n","\n","        nn3 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n","        self.conv3 = GINConv(nn3)\n","        self.bn3 = torch.nn.BatchNorm1d(dim)\n","\n","        nn4 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n","        self.conv4 = GINConv(nn4)\n","        self.bn4 = torch.nn.BatchNorm1d(dim)\n","\n","        nn5 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n","        self.conv5 = GINConv(nn5)\n","        self.bn5 = torch.nn.BatchNorm1d(dim)\n","\n","        self.fc1_xd = Linear(dim, output_dim)\n","\n","\n","        # BertModel로 단백질 서열 표현을 위한 초기화\n","        self.prot_bert_model = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n","        self.prot_tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n","        # prot_bert_embedding_dim 정의\n","        self.prot_bert_embedding_dim = self.prot_bert_model.config.hidden_size\n","\n","        # 층 결합\n","        self.fc1 = nn.Linear(output_dim + self.prot_bert_embedding_dim, 1024)\n","        self.fc2 = nn.Linear(1024, 256)\n","        self.out = nn.Linear(256, self.n_output)\n","\n","\n","    def forward(self, data):\n","        x, edge_index, batch = data.x, data.edge_index, data.batch\n","        target = data.target\n","\n","        x = F.relu(self.conv1(x, edge_index))\n","        x = self.bn1(x)\n","        x = F.relu(self.conv2(x, edge_index))\n","        x = self.bn2(x)\n","        x = F.relu(self.conv3(x, edge_index))\n","        x = self.bn3(x)\n","        x = F.relu(self.conv4(x, edge_index))\n","        x = self.bn4(x)\n","        x = F.relu(self.conv5(x, edge_index))\n","        x = self.bn5(x)\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1_xd(x))\n","        x = F.dropout(x, p=0.2, training=self.training)\n","\n","\n","        # 여러 개의 단백질 시퀀스 처리\n","        prot_features_list = []\n","        for sequence in target:\n","            sequence_Example = sequence\n","            sequence_Example = re.sub(r\"[UZOB]\", \"X\", sequence_Example)\n","            encoded_input = self.prot_tokenizer(sequence_Example, return_tensors='pt')\n","            outputs = self.prot_bert_model(**encoded_input)\n","            prot_features = outputs.last_hidden_state.mean(dim=1)\n","            prot_features_list.append(prot_features)\n","\n","        # 단백질 특질 결합, 평균 계산을 통해 최종 단백질 특질 생성\n","        prot_features_combined = torch.stack(prot_features_list, dim=0)\n","        prot_features_combined = prot_features_combined.view(-1, self.prot_bert_embedding_dim)\n","\n","        # GIN 특징과 단백질 특질 결합\n","        combined_features = torch.cat((x, prot_features_combined), dim=1)\n","\n","\n","        # 이후 모델 처리\n","        xc = self.fc1(combined_features)\n","        xc = self.relu(xc)\n","        xc = self.dropout(xc)\n","        xc = self.fc2(xc)\n","        xc = self.relu(xc)\n","        xc = self.dropout(xc)\n","        out = self.out(xc)\n","\n","        return out"]},{"cell_type":"code","source":["# Binding Affinity 예측\n","def make_prediction(model, ligand_data, protein_sequence):\n","    model.eval()\n","\n","    # 리간드 그래프 데이터를 PyTorch Geometric 데이터 객체로 변환\n","    c_size, features, edge_index = smiles_to_graph(ligand_data)\n","\n","    # PyTorch Geometric 데이터 객체 생성\n","    ligand_data = DATA.Data(\n","        x=torch.tensor(features, dtype=torch.float),\n","        edge_index=torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n","    )\n","\n","    # 단백질 서열 입력\n","    protein_sequence = re.sub(r\"[UZOB]\", \"X\", protein_sequence)\n","    encoded_input = model.prot_tokenizer(protein_sequence, return_tensors='pt')\n","    protein_tensor = model.prot_bert_model(**encoded_input).last_hidden_state.mean(dim=1)\n","\n","    # GIN Layer\n","    x = F.relu(model.conv1(ligand_data.x, ligand_data.edge_index))\n","    x = model.bn1(x)\n","    x = F.relu(model.conv2(x, ligand_data.edge_index))\n","    x = model.bn2(x)\n","    x = F.relu(model.conv3(x, ligand_data.edge_index))\n","    x = model.bn3(x)\n","    x = F.relu(model.conv4(x, ligand_data.edge_index))\n","    x = model.bn4(x)\n","    x = F.relu(model.conv5(x, ligand_data.edge_index))\n","    x = model.bn5(x)\n","    x = global_add_pool(x, ligand_data.batch)\n","    x = F.relu(model.fc1_xd(x))\n","    x = F.dropout(x, p=0.2, training=model.training)\n","\n","    # 약물과 단백질 표현 결합\n","    combined_features = torch.cat((x, protein_tensor), dim=1)\n","\n","    # 최종 예측\n","    with torch.no_grad():\n","        output = model.fc1(combined_features)\n","        output = model.relu(output)\n","        output = model.dropout(output)\n","        output = model.fc2(output)\n","        output = model.relu(output)\n","        output = model.dropout(output)\n","        output = model.out(output)\n","\n","    # 예측 결과 반환\n","    return output.item()\n","\n","# 저장된 모델 파일 경로\n","model_file_name = '/content/drive/My Drive/0923_cs/model_GINConvNet_kiba.model'\n","\n","# 모델 클래스 인스턴스 생성\n","model = GINConvNet(num_features_xd=78, num_features_xt=3872, output_dim=128)\n","\n","# 저장된 모델 가중치 로드\n","model.load_state_dict(torch.load(model_file_name))\n","\n","# 평가 모드\n","model.eval()\n","\n","# 입력받을 Ligands(smiles), Protein(fasta)\n","ligand_data = 'O=C(NCCc1cccs1)N1CC=C(c2c[nH]c3ncccc23)CC1'  # 예측하고자 하는 약물 데이터\n","protein_sequence = 'MASSSGSKAEFIVGGKYKLVRKIGSGSFGDIYLAINITNGEEVAVKLESQKARHPQLLYESKLYKILQGGVGIPHIRWYGQEKDYNVLVMDLLGPSLEDLFNFCSRRFTMKTVLMLADQMISRIEYVHTKNFIHRDIKPDNFLMGIGRHCNKLFLIDFGLAKKYRDNRTRQHIPYREDKNLTGTARYASINAHLGIEQSRRDDMESLGYVLMYFNRTSLPWQGLKAATKKQKYEKISEKKMSTPVEVLCKGFPAEFAMYLNYCRGLRFEEAPDYMYLRQLFRILFRTLNHQYDYTFDWTMLKQKAAQQAASSSGQGQQAQTPTGKQTDKTKSNMKGF'\n","\n","# 예측 수행\n","prediction = make_prediction(model, ligand_data, protein_sequence)\n","\n","# 결과 출력\n","print('예측 결과:', prediction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xi-uW4eN5UnC","executionInfo":{"status":"ok","timestamp":1700138990442,"user_tz":-540,"elapsed":38142,"user":{"displayName":"ᄒᄋ","userId":"02524461225617544295"}},"outputId":"a123c44c-1d38-4c38-deb9-b5a628ecf683"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["예측 결과: 11.730953216552734\n"]}]}]}